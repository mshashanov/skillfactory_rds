{"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport cv2\nimport sys\nimport os\nimport re, math, random, time, gc, string, pathlib, itertools\nimport shutil\n\n\ndef clear_directory(path):\n    is_exist_before = os.path.exists(path)\n    if is_exist_before:\n        shutil.rmtree(path)\n    is_exist_after = os.path.exists(path)\n    if not is_exist_before:\n        print('Directory is not exist')\n    if is_exist_after:\n        print('Directory is exist after')\n\n\ndef plot_classes_hist(values):\n    plt.figure()\n    sns.countplot(x=values)\n    plt.xlabel('')\n    plt.ylabel('')\n    plt.title('Classes histogram')\n    plt.grid()\n    plt.show()\n\n\ndef plot_history(history):\n    fig, axs = plt.subplots(1, 2, figsize=(16, 5))\n\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(len(acc))\n\n    axs[0].plot(epochs, acc, 'b', label='Training acc')\n    axs[0].plot(epochs, val_acc, 'g', label='Validation acc')\n    axs[0].set_title('Training and validation accuracy')\n    axs[0].set_xlabel('epochs')\n    axs[0].legend()\n    axs[0].grid()\n\n    axs[1].plot(epochs, loss, 'b', label='Training loss')\n    axs[1].plot(epochs, val_loss, 'g', label='Validation loss')\n    axs[1].set_title('Training and validation loss')\n    axs[1].set_xlabel('epochs')\n    axs[1].legend()\n    axs[1].grid()\n\n    plt.show()\n\n\ndef show_first_images(generator, count=6, labels=True, figsize=(20, 5), normalized=False):\n    generator = itertools.islice(generator, count)\n    fig, axes = plt.subplots(nrows=1, ncols=count, figsize=figsize)\n    for batch, ax in zip(generator, axes):\n        if labels:\n            img_batch, labels_batch = batch\n            img, label = img_batch[0], np.argmax(labels_batch[0]) # берем по одному изображению из каждого батча\n        else:\n            img_batch = batch\n            img = img_batch[0]\n        if not normalized:\n            img = img.astype(np.uint8)\n        ax.imshow(img)\n        # метод imshow принимает одно из двух:\n        # - изображение в формате uint8, яркость от 0 до 255\n        # - изображение в формате float, яркость от 0 до 1\n        if labels:\n            ax.set_title(f'Class: {label}')\n    plt.grid(False)\n    plt.show()\n    \n    \ndef print_col_info(data, num_dec=1, num_categories=4):\n    value_counts = data.value_counts(normalize=True, ascending=False)\n    if len(value_counts) > num_categories:\n        value_counts = value_counts.iloc[:num_categories]\n    value_counts = value_counts.multiply(100).round(num_dec)\n    value_counts = value_counts.apply(lambda x: str(x) + ' %')\n    display(value_counts)\n    print(f\"Num of missing values: {data.isna().sum()}\")\n    \n\ndef plot_top_categories(train, test, col, num_dec=1, num_categories=4, rotation=None):\n    train = train.copy()\n    test = test.copy()\n    if (col in ['verified', 'has_image', 'has_feature', 'has_similar_item', 'is_amazon_customer', 'is_kindle_customer']):\n        train[col] = get_verified_str(train[col])\n        test[col] = get_verified_str(test[col])\n\n    train_value_counts = train[col].value_counts(normalize=True, ascending=False)\n    train_num_missing = train[col].isna().sum()\n    if len(train_value_counts) > num_categories:\n        train_value_counts = train_value_counts.iloc[:num_categories]\n    \n    test_value_counts = test[col].value_counts(normalize=True, ascending=False)\n    test_num_missing = test[col].isna().sum()\n    if len(test_value_counts) > num_categories:\n        test_value_counts = test_value_counts.iloc[:num_categories]\n    \n    train_value_counts = train_value_counts.multiply(100).round(num_dec)\n    test_value_counts = test_value_counts.multiply(100).round(num_dec)\n    \n    train_values = break_long_names(train_value_counts.index)\n    test_values = break_long_names(test_value_counts.index)\n    \n    fig, axs = plt.subplots(1, 2, figsize=(15, 4))\n    sns.barplot(y=train_value_counts.values, x=train_values, ax=axs[0])\n    axs[0].grid(True)\n    axs[0].set_xlabel('')\n    axs[0].set_ylabel('percent')\n    if train_num_missing == 0:\n        axs[0].set_title('train')\n    else:\n        axs[0].set_title(f'train, {train_num_missing} missing')\n    \n    sns.barplot(y=test_value_counts.values, x=test_values, ax=axs[1])\n    axs[1].grid(True)\n    axs[1].set_xlabel('')\n    axs[1].set_ylabel('percent')\n    if test_num_missing == 0:\n        axs[1].set_title('test')\n    else:\n        axs[1].set_title(f'test, {test_num_missing} missing')\n    \n    fig.suptitle(col)\n    if rotation != None:\n        plt.setp(axs[0].get_xticklabels(), rotation=rotation)\n        plt.setp(axs[1].get_xticklabels(), rotation=rotation)\n    plt.show()\n    \n    \ndef get_verified_str(col_data):\n    true_val = 'True' # 'True'\n    false_val = 'False' # 'False'\n    verified_dict = {0: false_val, False: false_val, 'False': false_val, 1: true_val, True: true_val, 'True': true_val}\n    return col_data.map(verified_dict)\n\n\ndef break_long_names(names):\n    len_name = 25\n    short_names = []\n    for name in names:\n        if type(name) != type('') or len(name) < len_name:\n            short_names.append(name)\n        else:\n            sep = '&'\n            if sep in name:\n                short_names.append(name.replace(sep, sep+os.linesep))\n            else:\n                short_names.append(name[:len_name] + os.linesep + name[len_name:])\n    else:\n        return short_names\n    \n    \ndef plot_num_col_unified(train, test, col):\n    fig, axs = plt.subplots(1, 2, figsize=(15, 4/2))\n    data = train\n    \n    try:\n        sns.distplot(data[col], ax=axs[0])\n    except:\n        sns.distplot(data[col], ax=axs[0], kde_kws={'bw': 0.1})\n    \n    axs[0].set_title('train')\n    axs[0].set_xlabel('')\n    axs[0].grid(True)\n       \n    data = test\n    \n    try:\n        sns.distplot(data[col], ax=axs[1])\n    except:\n        sns.distplot(data[col], ax=axs[1], kde_kws={'bw': 0.1})\n    \n    axs[1].set_title('test')\n    axs[1].set_xlabel('')\n    axs[1].grid(True)\n    \n    fig.set_figheight(5)\n    fig.set_figwidth(15)\n    fig.suptitle(col)\n    plt.show()    \n    \n    \ndef plot_learning_rate(lr_list, num_epochs):\n    plt.figure()\n    plt.plot(range(0,num_epochs+1), lr_list, 'b', label='Exponential Decay')\n    plt.xlabel('epochs')\n    plt.ylabel('')\n    plt.title('Learning Rate')\n    plt.legend()\n    plt.xlim(0, num_epochs)\n    # plt.ylim(0, LR)\n    plt.grid()\n    plt.show()\n    \n    \n    \n    \n    \n    ","metadata":{"collapsed":false,"_kg_hide-input":false,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]}]}